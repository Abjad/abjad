<title>Why MIDI is not enough</title>

<h1>Why MIDI is not enough</h1>
<p>
Given that Abjad models written musical score, it might seem odd for MIDI to be even mentioned in this manual. 
Yet, until fairly recently, MIDI has played a role (sometimes tangential, other times fundamental) in a variety of software tools related to music notation and engraving.
</p>

<h2>A very brief overview of MIDI</h2>
<p>
MIDI (Musical Instrument Digital Interface) was first introduced in 1981 by Dave Smith, the founder of Sequential Circuits. 
The original purpose of MIDI was to allow the communication between different electronic musical instruments; more specifically, to allow one device to send <b>control</b> data to another device. Typical messages might be "note On" (play a <em>note</em>) "note Off" (turn off a <em>note</em>). 
A MIDI "note" message, for example, is composed of three bytes: the first byte (the Status byte) tells the device what kind of message this is (e.g. a Note On message). 
The second byte encodes key number (which key was pressed) and the third byte, velocity (how hard the key was pressed). 
It should be clear that a <em>Note</em> in this context means something very different than <em>Note</em> in the context of a traditional printed score. 
While the bias towards keyboard interfaces is clear in the definition of the MIDI Note control message, one can still give the MIDI note a more general use by reinterpreting "key number" as pitch and "velocity" as loudness, the usual perceptual correlates of these control changes as well as the most meaningful musical parameters in western music. 
</p>

<p>
With the subsequent proliferation of music production software, the SMF (Standard Midi File) was introduced to allow the recording and storage of the control data from a MIDI stream. 
The SMF required a time stamp to keep track of when control messages took place. These are called "delta-times" in the SMF specification:
<q>The MTrk chunk type is where actual song data is stored. It is simply a stream of MIDI events (and non-MIDI events), preceded by delta-time values.</q>
In combination with the MIDI Note message, the addition of duration now allowed one to have a minimal but sufficient <b>machine</b> representation--a machine score--of music requiring only these parameters: duration, pitch and loudness. Such is the case of most piano music.  
</p>

<h2>Limitations of MIDI from the point of view of score modeling</h2>
<p>
But, alas, there is much more information in a printed score that can not be practically encoded in a SMF. Common musical notions such as meter, clef, key signature, articulation, to name only a few, are ignored. 
A desire to include some of these concepts in MIDI is evident in the inclusion of some so called <em>meta-events</em>.
From the SMF specification: <q>< meta-event> specifies non-MIDI information useful to this format or to sequencers...</q>.
Examples of <em>meta-events</em> are <em>Time Signature</em> and <em>Key Signature</em>. 
In addition to the semantic elements just mentioned, there are also the typographical elements (such as line thickness, spacing, color, fonts, etc.) that all printed scores carry. This extra layer of information is completely absent in a SMF.
<!--How could all this information to be represented in MIDI? -->
However, from the point of view of encoding a printed score, the main limitation of MIDI is not the lack musical features or the absence of typographical data, but the assumption that musical durations, pitches and loudnesses can be each fully and efficiently encoded with integers or even fractions. In a printed score, this is not the case for any of them. 
MIDI encodes only <em>magnitudes</em>: time interval magnitudes, pitch interval magnitudes, velocity magnitudes. While these may be sufficient attributes for an automated piano performance, they are not all the attributes of notes in a printed score.
</p>


<h3>Written Note Durations vs. MIDI delta-times</h3>
<p>
Assume a fixed tempo has been set.
Assume that all magnitudes are represented with (and limited to) rational numbers.
A time interval magnitude <i>d</i> = 1/4 has an infinity of equivalent representations in terms of magnitude:
</p>
<i>d</i> = 1/4 = 1/8 * 2 = 1/8 + 1/16 * 2 ... etc. 

<p>
While equivalent in magnitude, these are not the same notated durations:
</p>
<abjad>
   hide> m1 = Measure((1, 4), [Note(0, (1, 4))])
   hide> m1.meter.transparent = True
   hide> m2 = Measure((1, 4), Note(0, (1, 8)) * 2)
   hide> Tie(m2)
   hide> m2.meter.transparent = True
   hide> m3 = Measure((1, 4), [Note(0, (1, 8))] + Note(0, (1, 16)) * 2)
   hide> Tie(m3)
   hide> m3.meter.transparent = True
   hide> r = RhythmicStaff([m1, m2, m3])
   hide> show(r)
</abjad>

<h3>Written Note Pitch vs. MIDI note-on</h3>
<p>
A similar thing happens with pitches. In MIDI, key (pitch) number 61 is a half tone above middle C. But how is this pitch to be notated? As a C sharp or a B flat?
</p>
<abjad>
   hide> m1 = Measure((1, 4), [Note(1, (1, 4))])
   hide> m1.meter.transparent = True
   hide> m2 = Measure((1, 4), [Note(('df', 4), (1, 4))])
   hide> m2.meter.transparent = True
   hide> r = Staff([m1, m2])
   hide> show(r)
</abjad>

<h2>Conclusion</h2>
<p>
MIDI was not designed for score representation.  MIDI is a simple communication protocol intended for real-time control. As such, it naturally lacks the adequate model to represent the full range of information found in printed scores.  
</p>
