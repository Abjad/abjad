1.  Notice that the SegmentSpecification.set_divisions() 'truncate' keyword means two things.
    It means truncate last division in section. It also means restart divisions at
    beginning of following section. Implement a SegmentSpecification.set_divisions()
    boolean 'restart' keyword to separate these functions. When restart=True
    then truncate will always effectively be interpreted as true.

2.  Can start_segment_identifier properties eventually be completely removed from model?
    What should be possible is for code to look at any timespan expression and get start segment specification.
    There is in fact an Interpreter.get_start_segment_specification() method right now.
    How does this relate to the "reanchoring" of settings during interpretation?

3.  Rename _set_start_segment_identifier().
    Maybe should be called _set_anchor(). Not sure.
    In fact it's possible that the entire notion of "start segment identifier" reduces to "anchor".
    If that turns out to be the case then "start segment specification" is
    something like "anchor segment specification".
    And more generally we have "anchor specification" to allow both score- and segment-anchoring.

4.  Implement some sort of "cake slice" management interface on SegmentSpecification and ScoreSpecification.
    Currently we must use ...
        selector = red_segment.select_segment_offsets(Offset(3, 16), Offset(6, 16))
        rhythm = red_segment.select_leaves('Voice 1', timespan=selector)
        blue_segment.set_rhythm(rhythm, contexts=['Voice 1'])
        rhythm = red_segment.select_leaves('Voice 2', timespan=selector)
        blue_segment.set_rhythm(rhythm, contexts=['Voice 2'])
        rhythm = red_segment.select_leaves('Voice 3', timespan=selector)
        blue_segment.set_rhythm(rhythm, contexts=['Voice 3'])
        rhythm = red_segment.select_leaves('Voice 4', timespan=selector)
        blue_segment.set_rhythm(rhythm, contexts=['Voice 4'])
    ... when it might be possible to use ...
        selector = red_segment.select_segment_offsets(Offset(3, 16), Offset(6, 16))
        selected_voices = ['Voice 1', 'Voice 2', 'Voice 3', 'Voice 4']
        rhythm = red_segment.select_leaves(selected_voices, timespan=selector)
        blue_segment.set_rhythm(rhythm, contexts=selected_voices)
    ... instead.
    This will simplify the X9 composer interface.

5.  Unskip all experimental tests before 2.11 build.

6.  Author tests to make sure that persistent overlapping division selectors 
    can be overwritten in a subsequent segment.
    See test_multiple_segment_solo__persistent_overlapping_division_selectors_05().

7.  Looks like callback stacks may not be copied over from segment to segment for persistent settings.
    Fix test_multiple_segment_solo__persistent_overlapping_division_selectors_03() to debug.

8.  Finish timerelationtools class docstrings before 2.11 build.

9.  Finish timespantools package docstrings before 2.11 build.

10. Add examples to the docstrings of all experimental class methods and properties before 2.11 build.

11. Extend OffsetExpression with an 'offset_callbacks' stack.
    Modifier methods include OffsetExpression.translate() and possibly others.

12. Add a test to show this:
        note_selector = red_segment.select_notes_and_chords('Voice 1')[10:11]
        offset = note_selector.stop_offset

13. Add some tests to show this:
        measures = red_segment.select_measures('Voice 1')
        measures = measures[10:20]
        measures = measures[2:4]
    This will show getitem composition.

14. Add some tests to show this:
        segments = score_specification.select_segments()['red':('blue'+1)]
        middle_part = segments.set_offset(start=(3, 4), stop=(-3, 4))
        score_specification.set_divisions([(1, 16)])
        middle_part.set_divisions([(3, 16)])
    This will show setting divisions for (potentially) more than one segment.

15. Add some tests to show this:
        segments = score_specification.select_segments()['red':('blue'+1)]
        middle_measures = segments.select_measures('Voice 1')[3:6]
    This will show selecting measures from (potentially) more than one segment.

16. Add some tests to show this:
        measures = red_segment.select_measures('Voice 1')[10:20]
        middle_third_of_measures = measures.partition_by_ratio((1, 1, 1))[1]
    This will show partitioning only part of a segment's measures.

17. Add some tests to show this:
        measures = red_segment.select_measures('Voice 1')
        middle_third_of_measures = measures.partition_by_ratio((1, 1, 1))[1]
        measure = middle_third_of_measures[:1]
    This will show slice selection following partition.

18. Add some tests to show this:
        first_half_of_red_segment = red_segment.timespan.divide_by_ratio((1, 1))[0]
        measures = first_half_of_red_segment.select_measures('Voice 1')
    This will show selecting measures that start during a duration-partitioned part of segment.

19. Add test to show this:
        offset = score_specification.start_offset.translate(Duration(32, 5))
        lookup = offset.look_up_rhythm_setting('Voice 1')
    Then add composer interface affordance for this:
        offset = score_specification.offset(Offset(32, 5))
        lookup = offset.look_up_rhythm_setting('Voice 1')

20. Afford rhythm setting lookup of parseable string. This will make ...
        red_segment.set_rhythm("c'32 [ c'16 c'16. ]", contexts=['Voice 1'])
        voice_1_rhythm_command = red_segment.timespan.start_offset.look_up_rhythm_setting('Voice 1')
        red_segment.set_rhythm(voice_1_rhythm_command, contexts=['Voice 2'])
    ... interpret correctly.
    Then make X5 work with rhythm setting lookup instead of rhythm selector.

21. Change primary usage pattern from ...
        score_template = scoretemplatetools.GroupedRhythmicStavesScoreTemplate(staff_count=1)
        score_specification = specificationtools.ScoreSpecification(score_template)
    ... to ...
        score_template = scoretemplatetools.GroupedRhythmicStavesScoreTemplate(staff_count=1)
        score_specification = settingtools.ScoreSpecificationInterface(score_template)
    ... so that composers only ever interact with interfaces.

23. Clarify return types of all _evaluate() methods.
    Some _evaluate() methods returns VoicedStartPositionedPayloadExpression objects.
    Some _evaluate() methods return lists or tuples.
    Perhaps these are the only two acceptable evaluation return types.

24. Why do RegionCommand concrete classes implement an _evaluate() method?
    RegionCommand classes are not expressions.
    Perhaps an _execute() method? Or perhaps a different pattern altogether?

25. Assert that callbacks apply only to payload expressions.

26. Do something about RhythmMakeExpression.
    Right now the class inherits from Expression.
    But the _evaluate() method is set to raise NotImplementedError.
    So perhaps the class is not really an expression?
    The class is also sometimes the target of callback application.
    Is there a way to make this not be the case?
    Ideally only payload expressions should be the target of callback application.
