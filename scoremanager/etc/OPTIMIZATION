Note that as of r9,872 it takes only 181 function calls to initialize 
the score manager ...

    >>> expr = 'ide = scoremanager.idetools.AbjadIDE(is_test=True)'
    >>> systemtools.IOManager.profile_expr(expr)
    181 function calls in 0.000 seconds

... but that it takes 819,997 function calls to start and immediately quit 
the score manager a first time and then significantly fewer function calls 
on successive tests:

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    819997 function calls (819894 primitive calls) in 0.734 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    241391 function calls in 0.220 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    241391 function calls in 0.220 seconds

CONCLUSION: don't know what's going on here but it's clear that the score 
manager takes quite a few unnecessary steps on start-up. AbjadIDE start 
up should be as simple as listing the names of all scores in the system, 
possibly with the additional work of inspecting each score package metadatum file 
for date of composition. All of that should take far fewer than 820,000 
function calls. Optimizing score manager start up should save as much as 
0.7 seconds on each score manager-initiated test.

OBSERVATION: Note that the following ...

    def make_score_selection_menu(self):
        #menu, menu_section = self._io_manager._make_menu(
            where=self._where, is_numbered=True)
        menu, menu_section = self._io_manager._make_menu(
            where='foo', is_numbered=True)
        menu_section.menu_entries = \
            self.score_package_wrangler._make_asset_menu_entries()
        return menu

... reduces score manager start-up from 820,000 function calls to 
153,000 function calls. Removing the call to self._where removes the call 
to inspect.stack(). This was tricky to find because 
systemtools.IOManager.profile_expr('inspect.stack()') is lean.
The function must be called inside a complex stack to reveal its true cost.

CONCLUSION: Stack inspection can not be a mandatory part of menu creation
because stack inspection is expensive.


### r10,249 ###

As of r10,249 it takes 6,658 function calls to initialize the score manager ...

    >>> expr = 'ide = scoremanager.idetools.AbjadIDE(is_test=True)'
    >>> systemtools.IOManager.profile_expr(expr)
    6658 function calls (6646 primitive calls) in 0.008 seconds

   Ordered by: cumulative time
   List reduced from 147 to 12 due to restriction <12>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.008    0.008 <string>:1(<module>)
        1    0.000    0.000    0.008    0.008 AbjadIDE.py:11(__init__)
        6    0.000    0.000    0.008    0.001 PackagesystemAssetWrangler.py:8(__init__)
        6    0.000    0.000    0.008    0.001 package_path_to_path.py:4(package_path_to_path)
        6    0.000    0.000    0.007    0.001 Configuration.py:22(__init__)
        6    0.000    0.000    0.007    0.001 Configuration.py:16(__init__)
        2    0.000    0.000    0.003    0.001 MaterialManagerWrangler.py:12(__init__)
        1    0.000    0.000    0.003    0.003 MaterialPackageWrangler.py:37(__init__)
     12/6    0.000    0.000    0.002    0.000 configobj.py:1187(__init__)
     12/6    0.000    0.000    0.002    0.000 configobj.py:1245(_load)
        6    0.000    0.000    0.002    0.000 configobj.py:2116(validate)
       12    0.001    0.000    0.002    0.000 configobj.py:1533(_parse)

... as opposed to the 181 function calls it took in r9,872.

This is most likely due to the integration of Configuration.
This increase from 181 to 6,658 is probably nothing to worry about.

But note that it takes between 325,000 and 323,000 function calls to start 
and then immediately quit the score manager, totaling ~0.4 seconds on the iMac:

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    325311 function calls (324734 primitive calls) in 0.407 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    323222 function calls (322706 primitive calls) in 0.435 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    323222 function calls (322706 primitive calls) in 0.395 seconds

This represents an increase from 240,000 function calls to 323,000 function
calls (or 0.22 seconds to 0.40 seconds) from r9,872 to r10,249.
The performance of r10,249 is only half as fast as r9,872 at the basic
task of starting the score manager and then immediately quitting.


### r10,250 ###

Turning on the quick-and-dirty caching code included in r10,250 gives the 
following results:

    >>> expr = 'ide = scoremanager.idetools.AbjadIDE(is_test=True)'
    >>> systemtools.IOManager.profile_expr(expr)
    6658 function calls (6646 primitive calls) in 0.008 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    8417 function calls (8382 primitive calls) in 0.009 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    8169 function calls (8157 primitive calls) in 0.009 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    8169 function calls (8157 primitive calls) in 0.009 seconds

CONCLUSION: the quick-and-dirty caching code turned on in r10,250 effectively 
eliminates *all* the effort associated with starting the score manager. This 
shows that the effort involved in starting the score manager comes exclusively 
from the call ...
    menu_section.menu_entries = self.score_package_wrangler._make_asset_menu_entries()
... found in the score manager. The pytest battery runs in 160 seconds on the 
iMac with caching turned off; the pytest battery runs in 94 seconds on the 
iMac with caching turned on.

PROSPECTUS: Should caching become a permament part of the system? There are 
risks associated with caching; these all come from the work necessary to keep 
the cache up to date. Perhaps more to the point is the fact that every rebuild 
of the main menu ...
    menu_section.menu_entries = self.score_package_wrangler._make_asset_menu_entries()
... now costs ~320,000 fuction calls (~0.4 seconds). So whether caching is left
permanently turned on or not, it is clear that ...
    menu_section.menu_entries = self.score_package_wrangler._make_asset_menu_entries()
... must be optimized regardless.
Probably what should happen is that ...
    menu_section.menu_entries = self.score_package_wrangler._make_asset_menu_entries()
... should be optimized and caching should be left permanently turned on. 
Why? Because leaving caching turned on gives almost a 80% speed *when running 
the test battery*. That reason alone is probably enough to leave caching 
turned on.


### r10,251 ###

Revision r10,251 fives an inefficiency in 
package_path_to_path() and the same inefficiency in 
path_to_package(). Specifically, a 
Configuration object was being instantiated for each and every
call to both of these functions; note that there is disk read time incurred 
every time a Configuration object is istantiated.

RESULTS: correcting the inefficiency produces the following results.
Note that all of these results are with caching turned off:

    >>> expr = 'ide = scoremanager.idetools.AbjadIDE(is_test=True)'
    >>> systemtools.IOManager.profile_expr(expr)
    760 function calls in 0.001 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    77889 function calls (77828 primitive calls) in 0.097 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    75800 function calls in 0.073 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    75800 function calls in 0.073 seconds

Also, the pytest battery now runs in 46 seconds on the iMac.

CONCLUSION: these are extremely good results. The identified inefficiency was 
the problem.

It is possible that turning caching back on could increase pytest battery 
performance. Such will results will be recorded in a future entry to this ll.


### r10,252 ###

Revision r10,252 turns caching back on.

RESULTS: pytest battery time decreases from 46 seconds to 37 seconds. 
Also these:

    >>> expr = 'ide = scoremanager.idetools.AbjadIDE(is_test=True)'
    >>> systemtools.IOManager.profile_expr(expr)
    760 function calls in 0.001 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    2663 function calls (2640 primitive calls) in 0.003 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    2415 function calls in 0.002 seconds

    >>> systemtools.IOManager.profile_expr("ide._run(input_='q')")
    2415 function calls in 0.002 seconds

CONCLUSION: quick-and-dirty caching saves about 20% of pytest run time for 
scoremanager. So a reasonable path forward is to leave caching on *during
development* and then turn it off before shipping public releases.


### 2014-03-17 ###

Here are data for running the py.test battery with where-tracking turned off
versus running with where-tracking turned on:

With where-tracking turned off:

    446 passed, 12 skipped in 53.16 seconds
    446 passed, 12 skipped in 52.37 seconds
    446 passed, 12 skipped in 52.20 seconds
    average time: 52.58 seconds

With where-tracking turned on:

    446 passed, 12 skipped in 56.89 seconds
    446 passed, 12 skipped in 55.81 seconds
    446 passed, 12 skipped in 55.69 seconds
    average time: 56.13 seconds

Here are function counts for the same thing:

With where-tracking turned off:

    >>> ide = scoremanager.idetools.AbjadIDE(is_test=True)
    >>> statement = 'ide._make_main_menu()'
    >>> print ide._session.io_manager.count_function_calls(
        statement,
        global_context=globals(),
        local_context=locals(),
        )
    2741

With where-tracking turned on:

    >>> ide = scoremanager.idetools.AbjadIDE(is_test=True)
    >>> statement = 'ide._make_main_menu()'
    >>> print ide._session.io_manager.count_function_calls(
        statement,
        global_context=globals(),
        local_context=locals(),
        )
    19690

RESULTS: there's about a 6.7% runtime cost to turning where-tracking on.

RESULTS: main menu production goes from ~3000 to ~20,000 function calls with
where-tracking turned on.

CONCLUSION: the extra function calls required to keep where-tracking turned on
result in a runtime overhead of only between 5 - 10%. It actually makes sense
to keep where-tracking turned on all the time. An even smarter approach will
keep where-tracking turned for all nontest sessions and leave where-tracking
turned off for all test sessions.
